
import torch # 텐서 생성, 연산
import torch.nn as nn # 신경망의 층 관련 라이브러리
import torch.optim as optim # 최적화 알고리즘
from torch.utils.data import DataLoader, Dataset, random_split, Subset
from torchvision import transforms, models, datasets
import numpy as np
from google.colab import drive
import os
from PIL import Image
import datetime
import glob
import random
from torch.utils.data import DataLoader, TensorDataset # TensorDataset -> X, y를 텐서형태로 나누기
import pandas as pd
from sklearn.preprocessing import LabelEncoder # label 전처리
from tqdm.notebook import tqdm # 에포크 상황 확인하기
from sklearn.model_selection import train_test_split

drive.mount('/content/drive')
data_dir = '/content/drive/MyDrive/Food_allergy/image'
checkpoint_path = '/content/drive/MyDrive/Food_allergy/checkpoint.pth'
log_path = '/content/drive/MyDrive/Food_allergy/epoch_accuracy_log.txt'

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ---------------------------------------------------
# 1. Dataset 클래스 정의 (가장 하위 폴더 = 클래스)
# ---------------------------------------------------
class CustomImageDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.samples = []
        self.classes = []
        self.class_to_idx = {}
        self.transform = transform

        # 가장 하위 폴더(이미지가 들어있는 폴더)를 클래스 폴더로 인식
        for root, dirs, files in os.walk(root_dir):
            if len(files) > 0:  # 이미지가 들어있는 폴더라면
                class_name = os.path.basename(root)
                if class_name not in self.class_to_idx:
                    self.class_to_idx[class_name] = len(self.classes)
                    self.classes.append(class_name)

                for file in files:
                    if file.lower().endswith(('png','jpg','jpeg','bmp')):
                        self.samples.append((os.path.join(root, file), self.class_to_idx[class_name]))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert("RGB")
        if self.transform:
            img = self.transform(img)
        return img, label

# ---------------------------------------------------
# 2. 데이터 로드 및 train/test 분할
# ---------------------------------------------------
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

dataset = CustomImageDataset(data_dir, transform=transform)
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)

num_classes = len(dataset.classes)

# ---------------------------------------------------
# 3. 모델 정의
# ---------------------------------------------------
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# ---------------------------------------------------
# 4. 체크포인트 불러오기
# ---------------------------------------------------
start_epoch = 0
if os.path.exists(checkpoint_path):
    checkpoint = torch.load(checkpoint_path, map_location=device)

    if "model_state_dict" in checkpoint:   # 제 코드 포맷
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        print(f"✅ 체크포인트 불러오기 성공 (epoch {start_epoch}부터 시작)")

    elif "model_state" in checkpoint:      # 기존에 저장한 포맷
        model.load_state_dict(checkpoint['model_state'])
        optimizer.load_state_dict(checkpoint['optimizer_state'])
        start_epoch = checkpoint['epoch'] + 1
        print(f"✅ (구버전) 체크포인트 불러오기 성공 (epoch {start_epoch}부터 시작)")

    else:  # 그냥 state_dict만 저장된 경우
        model.load_state_dict(checkpoint)
        print("⚠️ 모델 파라미터만 불러왔습니다. epoch=0부터 시작")

# ---------------------------------------------------
# 5. 학습 함수
# ---------------------------------------------------
def train(model, loader, optimizer, criterion, epoch):
    model.train()
    running_loss = 0.0
    for i, (inputs, labels) in enumerate(loader):
        inputs, labels = inputs.to(device), labels.to(device)

        # 순전파
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # 역전파
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        if (i+1) % 10 == 0:
            print(f"[Epoch {epoch+1}] Step {i+1}/{len(loader)}, Loss: {loss.item():.4f}")

    return running_loss / len(loader)

# ---------------------------------------------------
# 6. 평가 함수 (클래스별 정확도)
# ---------------------------------------------------
def evaluate(model, loader, classes, epoch, log_file):
    model.eval()
    correct = 0
    total = 0
    class_correct = [0]*len(classes)
    class_total = [0]*len(classes)

    with torch.no_grad():
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            correct += (preds == labels).sum().item()
            total += labels.size(0)

            for i in range(len(labels)):
                label = labels[i]
                class_total[label] += 1
                if preds[i] == label:
                    class_correct[label] += 1

    overall_acc = 100 * correct / total
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(f"Epoch {epoch+1}:\n")
        for i, classname in enumerate(classes):
            acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0
            f.write(f"  {classname}: {acc:.2f}%\n")
        f.write(f"  Overall: {overall_acc:.2f}%\n\n")

    print(f"✅ Epoch {epoch+1} 테스트 정확도: {overall_acc:.2f}%")
    return overall_acc

# ---------------------------------------------------
# 7. 학습 루프
# ---------------------------------------------------
num_epochs = 10
for epoch in range(start_epoch, num_epochs):
    loss = train(model, train_loader, optimizer, criterion, epoch)
    acc = evaluate(model, test_loader, dataset.classes, epoch, log_path)

    # 체크포인트 저장
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict()
    }, checkpoint_path)

    print(f"💾 체크포인트 저장 완료 (epoch {epoch+1})")

print("🎉 학습 완료")
